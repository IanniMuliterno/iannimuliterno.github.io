---
layout: post
title: A métrica KS
tags: [modelagem, classificação, ks]
---  

Olá quarenteners, como tá seu recorde de séries maratonadas?

Hoje passei, depois de muitos meses é verdade, para falar um pouco sobre uma métrica muito bem-quista para avaliar performance de modelos de classificação binária, a métrica KS. O motivo é simples, dentre as métricas de modelo de classificação mais adotadas ( Acurácia, sensibilidade, F1, curva ROC) ela é a mais caixa preta, então vamos mudar isso.

Antes de começar vamos definir ( ou relembrar, para alguns ), os conceitos de Taxa de Verdadeiro Positivo (TVP), Taxa de Verdadeiro Negativo (TVN), Taxa de Falso Positivo (TFP) e Taxa de Falso Negativo (TFN), considerando uma classificação binária onde 1 é positivo e 0 é negativo.

- <strong> TVP </strong>, é o quanto dos meus positivos são de fato classificados pelo modelo como positivos. `VP/(VP + FN)`, métrica conhecida como 'sensibilidade'.

- <strong> TVN </strong>, é o quanto dos meus negativos são de fato classificados pelo modelo como negativos. `VN/(VN + FP)`, métrica conhecida como 'especificidade'.

- <strong> TFP </strong>, é o quanto dos meus negativos são classificados como positivos pelo modelo. `FP/(FP + VN)`, métrica conhecida como Erro tipo I.

- <strong> TVP </strong>, é o quanto dos meus positivos são classificados como negativos pelo modelo. `FN/(FN + VP)`, métrica conhecida como Erro tipo II.

Agora sim é possível partir para a explicação do KS.

- 1. O modelo retorna probabilidades de sucesso. Primeiro, ordenamos as observações de forma descendente de acordo com essas probabilidades ;

- 2. Então calculamos para cada probabilidade ou faixa de probabilidade a proporção de positivos e negativos em relação a quantidade total de positivos. 

- 3. Calculamos as proporções acumuladas de positivos e negativos;

- 4. Plotamos as funções de distribuição acumulada para positivos e negativos e então é possível calcular a métrica KS como sendo a distância máxima entre as duas.

 Para ilustrar o passo a passo vamos fazer isso manualmente e comparar com o resultado da função `ks.test`, para isso vamos criar uma base sintética de 1000 observações.

```
label <- base::sample(c(0,1),1000,prob = c(.3,.7),replace = T) %>% as.factor()
letras <- base::sample(c("a","b","c"),1000,prob = c(.3,.5,.2),replace = T)
numers <- rgamma(1000, shape = 2) + rnorm(1000,7)*as.numeric(label)


modelo <- glm(label ~ letras + numers^2, family = binomial())
summary(modelo)

preditos <- ifelse(modelo$fitted.values > .5,1,0)

table(label,preditos)

#          preditos
# label     0   1
# 
#        0 273  25
#        1  23 679

# essa linha de código retorna o valor da área sob a curva ROC, 
# esperamos um valor o mais próximo possível de 1 para indicar que 
# o modelo consegue ajustar bem. O rande da métrica é [0,1].

Metrics::auc(actual = label, modelo$fitted.values)
#0.9891442
```

 O resultado de um modelo logístico aplicado a nossa base sintética retorna valores de VP, VN, FP e FN que sugerem uma classificação razoavelmente boa.

- VP = 679
- VN = 273
- FP = 25
- FN = 23


