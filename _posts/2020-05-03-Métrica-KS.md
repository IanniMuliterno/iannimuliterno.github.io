---
layout: post
title: A métrica KS
tags: [modelagem, classificação, ks]
---  

Olá quarenteners, como tá seu recorde de séries maratonadas?

Hoje passei, depois de muitos meses é verdade, para falar um pouco sobre uma métrica muito bem-quista para avaliar performance de modelos de classificação binária, a métrica KS. O motivo é simples, dentre as métricas de modelo de classificação mais adotadas ( Acurácia, sensibilidade, F1, curva ROC) ela é a mais caixa preta, então vamos desvendar um pouco sobre ela. Vale avisar que para uma boa compreensão desse  post você precisa conhecer o básico sobre modelos de classificação, pois vamos apenas relembrar alguns conceitos e pôr a mão na massa.

Antes de começar vamos relembrar o conceito de algumas métricas para justificar a importância da KS, essas métricas são: Taxa de Verdadeiro Positivo (TVP), Taxa de Verdadeiro Negativo (TVN), Taxa de Falso Positivo (TFP) e Taxa de Falso Negativo (TFN), considerando uma classificação binária onde 1 é positivo e 0 é negativo.

- <strong> TVP </strong>, é o quanto dos meus positivos são de fato classificados pelo modelo como positivos. `VP/(VP + FN)`, métrica conhecida como 'sensibilidade'.

- <strong> TVN </strong>, é o quanto dos meus negativos são de fato classificados pelo modelo como negativos. `VN/(VN + FP)`, métrica conhecida como 'especificidade'.

- <strong> TFP </strong>, é o quanto dos meus negativos são classificados como positivos pelo modelo. `FP/(FP + VN)`, métrica conhecida como Erro tipo I.

- <strong> TVP </strong>, é o quanto dos meus positivos são classificados como negativos pelo modelo. `FN/(FN + VP)`, métrica conhecida como Erro tipo II.

Observe que essas métricas dão resultados específicos e se avaliadas separadamente, podem dar a falsa impressão de que temos um modelo bem ajustado, por exemplo, o modelo pode ter baixa TFP e alta TVP ao mesmo tempo, inclusive esse tipo de problema é comum quando a variável binária que queremos prever é desbalanceada, pois se o modelo não recebe informação suficiente sobre uma das classes ele provavelmente não vai saber diferenciá-la da classe concorrente. 

 Agora sim é possível partir para a explicação do KS e entender porque é interessante aplicar.

 Essa métrica considera uma base de classificação binária e um modelo ajustado que retorne probabilidades da observação pertencer aos positivos. O passo a passo é :

- 1. Rodar o modelo de classificação para obter as probabilidades das observações possuírem resposta positiva. Primeiro, ordenamos as observações de forma descendente de acordo com essas probabilidades;

- 2. Então calculamos para cada probabilidade a proporção de positivos e negativos em relação a quantidade total de positivos. 

- 3. Calculamos as proporções acumuladas de positivos e negativos;

- 4. Plotamos as funções de distribuição acumulada para positivos e negativos e então é possível calcular a métrica KS como sendo a distância máxima entre as duas.

 Para ilustrar o passo a passo vamos fazer isso manualmente e comparar com o resultado da função `ks.test`, para isso vamos criar uma base sintética de 1000 observações.

```
label <- base::sample(c(0,1),1000,prob = c(.3,.7),replace = T) %>% as.factor()
letras <- base::sample(c("a","b","c"),1000,prob = c(.3,.5,.2),replace = T)
numers <- rgamma(1000, shape = 2) + rnorm(1000,7)*as.numeric(label)


modelo <- glm(label ~ letras + numers^2, family = binomial())
summary(modelo)

preditos <- ifelse(modelo$fitted.values > .5,1,0)

table(label,preditos)

#          preditos
# label     0   1
# 
#        0 254  29
#        1  20 697
```

 O resultado de um modelo logístico aplicado a nossa base sintética, com cutoff em 0.5 retorna os seguintes valores de VP, VN, FP e FN:

- VP = 697
- VN = 254
- FP = 20
- FN = 29

 Com isso podemos calcular a estatística KS como a diferença entre TVP e TFP, que vai depender do cutoff
 
 ```
 
cutoff <- seq(0,1,by = 0.001)
TVP <- TFP <- numeric()

for(i in 1:length(cutoff)){
  
  preditos <- ifelse(modelo$fitted.values > cutoff[i],1,0)
  
  store <- data.frame(preditos, label)
  
  VP <- store %>% summarise(sum((preditos == 1 & label == 1))) %>% as.numeric()
  FN <- store %>% summarise(sum((preditos == 0 & label == 1))) %>% as.numeric()
  FP <- store %>% summarise(sum((preditos == 1 & label == 0))) %>% as.numeric()
  VN <- store %>% summarise(sum((preditos == 0 & label == 0))) %>% as.numeric()
  
  TVP[i] <- VP/(VP + FN)
  TFP[i] <- FP/(FP + VN)
  
}



TVP[which(cutoff == .5)] - TFP[which(cutoff == .5)]
 ```
